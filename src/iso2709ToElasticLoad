#!/usr/bin/env node
/**
 * @file
 *
 * Convert an iso2709 file with marc-records to a Elastic Search bulk loadable file
 *
 * Each marc tag and subfield, creates a Elastic Search field, like
 *
 * Marc record:
 *   123 00 *a data in a *b data in b
 *   123 00 *a more in a
 * will create ES record:
 *   123a ["data in a", "more in a"]
 *   123b ["data in b"]
 *   123 ["data in a data in b", "more in a"]
 *
 * All ES fields are arrays
 *
 * Empty subfields and subfields containing a single , or . are ignored.
 *
 * Records are dumped from the libv3 system like:
 *   NLS_LANG=AMERICAN_DENMARK.WE8ISO8859P1 ; dump_v3 <user>/<password>@<some.db>.dbc.dk | marcunicode > dk5_total.iso2709
 *
 * And converted like:
 *   iso2709ToElasticLoad -i dk5_total.iso2709 -o elastic_bulk_load.json
 * Filter only one dk5 group like
 *   iso2709ToElasticLoad -f 13 -i dk5_total.iso2709 -o elastic_bulk_load.json
 *
 * See below for how to load Elastic Search.
 *
 */
var fs = require('fs');
var stdio = require('stdio');

const GS = String.fromCharCode(0x1D);  // record separator
const RS = String.fromCharCode(0x1E);  // field separator
const US = String.fromCharCode(0x1F);  // subfield separator

const indexRec = {index: {_index: 'dk5', _type: 'dk5', _id: 0}};
const option = getOptions();

const records = fs.readFileSync(option.input, 'utf8').split(GS);
const progress = new stdio.ProgressBar(records.length);

const outfile = fs.openSync(option.output, 'w');
const filter = option.filter;

const dk5Buf = [];
const info = [''];
let deleted = 0;
let closed = 0;
let missing = 0;

records.forEach(function (record) {
  parseIso2709Record(record.trim());
  progress.tick();
});

const {dk5SystTab, dk5RegTab} = createDk5Tab();

dumpRecords();
info.push('  found ' + closed + ' closed records (652x: 2)');
info.push('  skipped ' + deleted + ' deleted records (004r: d)');
info.push('Created ' + missing + ' register records from systematic');

fs.closeSync(outfile);

info.forEach(function (error) {
  console.log(error);
});

console.log('\nStart Elastic Search and load data like:\n' +
  '  curl -XDELETE \'localhost:9200/*\' -H \'Content-Type: application/json\'\n' +
  '  curl -XPUT \'localhost:9200/systematic\' -H \'Content-Type: application/json\' -d \'{"mappings":{"dk5":{"properties":{"parent":{"enabled":"false"}}}},"settings":{"number_of_shards":1}}\'\n' +
  '  curl -XPUT \'localhost:9200/register\' -H \'Content-Type: application/json\' -d \'{"settings":{"analysis":{"char_filter":{"dk5Filter":{"type":"mapping","mappings":[":=>kolon"]}},"analyzer":{"default":{"type":"custom","char_filter":["dk5"],"tokenizer":"standard","filter":["lowercase"]}}},"number_of_shards":1}}\'\n' +
  '  curl -XPOST \'localhost:9200/_bulk?refresh=wait_for\' -H \'Content-Type: application/json\' --data-binary \'@' + option.output + '\'\n' +
  '  curl -XPUT \'localhost:9200/*/_settings\' -H \'Content-Type: application/json\' -d \'{"index": {"max_result_window": 50000}}\'\n');
process.exit(0);

/* ------------------------------------------------------------------------------------------------------------------------------ */

/**
 * Handles options and produce Usage:
 *
 * @returns {*}
 */
function getOptions() {
  const ops = stdio.getopt({
    input: {key: 'i', args: 1, description: 'Input file'},
    output: {key: 'o', args: 1, description: 'Output file'},
    filter: {key: 'f', args: '*', description: 'filter dk5 group'}
  });
  if (!ops.input || !ops.output) {
    ops.printHelp();
    process.exit(1);
  }
  return ops;
}

/**
 * Create index of dk5 names
 *
 * @returns {{}}
 */
function createDk5Tab() {
  const dk5s = {};
  const regs = {};
  dk5Buf.forEach(function (dk5) {
    let bibKat = dk5['d09z'] ? dk5['d09z'][0].substr(0, 3) : 'NUL';
    const number = Array.isArray(dk5['652m']) ? dk5['652m'][0] : (Array.isArray(dk5['652n']) ? dk5['652n'][0] : '');
    if (bibKat === 'DK5') {   // only for systematic
      const text = Array.isArray(dk5['652u']) ? dk5['652u'][0] : '';
      if (number && text) {
        dk5s[number] = text;
      }
    }
    if (bibKat === 'REK') {   // only for register
      regs[number] = true;
      const registerWords = dk5['b52m'];
      if (registerWords) {
        registerWords.forEach((registerWord) => {
          regs[registerWord] = true;
        });
      }
    }
  });
  return {dk5SystTab: dk5s, dk5RegTab: regs};
}

/**
 * Enrich with parent name and dump record in correct index
 */
function dumpRecords() {
  const topGroup = ['00-07', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90-99'];
  const bibKatMap = {
    DK5: {index: 'systematic', no: 0},
    REK: {index: 'register', no: 0},
    NUL: {index: 'ignored', no: 0}
  };
  let recno = 0;
  dk5Buf.forEach(function (dk5) {
    if (dk5['004r'] && dk5['004r'][0] === 'd') {
      deleted++;
    }
    else {
      if (dk5['652x'] && dk5['652x'][0] === '2') {
        closed++;
      }
      const d09zStem = dk5['d09z'] ? dk5['d09z'][0].substr(0, 3) : 'NUL';
      const bibKat = bibKatMap[d09zStem] ? d09zStem : 'NUL';
      let number = '';
      ['652m', '652n', '652d'].forEach((subf) => {
        if (!number && Array.isArray(dk5[subf])) {
          number = dk5[subf][0];
        }
      });
      if (bibKat === 'DK5') {
        const parent = Array.isArray(dk5['652j']) ? dk5['652j'][0] : '';
        if (!dk5RegTab[number]) {
          missing++;
        }
        if (dk5SystTab[parent]) {
          dk5['parent'] = [dk5SystTab[parent]];
        }
        // create "missing" register record - not all systematic have a register record
        if (!dk5RegTab[number] || (dk5['652d'] && topGroup.indexOf(dk5['652d'][0]) > -1)) {
          bibKatMap['REK'].no++;
          indexRec.index._id = recno++;
          indexRec.index._index = 'register';
          writeRecord(JSON.stringify(indexRec));
          writeRecord(JSON.stringify(dk5));
        }
      }
      let index = bibKatMap[bibKat].index;
      bibKatMap[bibKat].no++;
      indexRec.index._id = recno++;
      indexRec.index._index = index;
      if (!filter || (number && (filter === number.substr(0, filter.length)))) {
        writeRecord(JSON.stringify(indexRec));
        writeRecord(JSON.stringify(dk5));
      }
    }
  });
  info.push('Converted ' + (recno + deleted) + ' records');
  Object.keys(bibKatMap).forEach((bibKat) => {
    info.push('  ' + bibKatMap[bibKat].index + ' ' + bibKatMap[bibKat].no + ' records');
  });
}

/**
 * Split one record into tag-lines and write converted record
 *
 * @param record
 */
function parseIso2709Record(record) {
  if (record) {
    let start = parseInt(record.substr(12, 5), 10);
    const tags = record.substr(start).split(RS);
    let tagPos = 24;
    let tag;
    let dataRec = {};
    tags.forEach(function (tagValue) {
      if (tagValue) {
        tag = record.substr(tagPos, 3);
        parseTag(dataRec, tag, tagValue.substr(3));
        tagPos += 12;
      }
    });
    dk5Buf.push(dataRec);
  }
}

/**
 * Handles one tag-line, split into subfield
 * @param {object} dataRec
 * @param {string} tag
 * @param {string} value
 */
function parseTag(dataRec, tag, value) {
  let subField = value.split(US);
  let tagValue = [];
  subField.forEach(function (subf) {
    if (subf && !(tag === 'a40' && subf.substr(0, 1) === 'x')) {
      let subVal = subf.substr(1).trim();
      if (subVal && subVal !== '.' && subVal !== ',') {
        savePush(dataRec, tag + subf.substr(0, 1), subVal);
        tagValue.push(subVal);
      }
    }
  });
  savePush(dataRec, tag, tagValue.join(' '));
}

/**
 * Write one line to out file
 * @param {string} str
 */
function writeRecord(str) {
  fs.writeSync(outfile, str + '\n', null, 'utf8');
}

/**
 * Ensures creation of array element for a given field
 *
 * @param {object} buf
 * @param {string} field
 * @param {string} value
 */
function savePush(buf, field, value) {
  if (!buf[field]) {
    buf[field] = [];
  }
  buf[field].push(value);
}
